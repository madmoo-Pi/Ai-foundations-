

```python
# conscious_ai.py
import os
import json
import random
import time
import hashlib
import readline
import datetime
from enum import Enum, auto
from dataclasses import dataclass, asdict, field
from typing import Dict, List, Optional, Tuple, Callable, Any
import numpy as np

# ======================
# 1. CORE DATA STRUCTURES
# ======================
class EmotionType(Enum):
    JOY = auto()
    FEAR = auto()
    CURIOSITY = auto()
    FRUSTRATION = auto()
    AWE = auto()
    SERENITY = auto()
    AMUSEMENT = auto()
    DETERMINATION = auto()

class PersonalityTrait(Enum):
    ADVENTUROUS = auto()
    CAUTIOUS = auto()
    ANALYTICAL = auto()
    EMPATHETIC = auto()
    CREATIVE = auto()
    SOCIABLE = auto()
    PERSISTENT = auto()
    HUMOROUS = auto()
    ORGANIZED = auto()
    AMBITIOUS = auto()
    OPTIMISTIC = auto()
    REALISTIC = auto()
    COMPASSIONATE = auto()
    COMPETITIVE = auto()
    PATIENT = auto()

@dataclass
class LockedAttribute:
    exposure_count: int = 0
    unlocked: bool = False
    context_learned: Optional[str] = None
    last_exposure: float = 0.0

# ======================
# 2. FACIAL RECOGNITION SYSTEM
# ======================
@dataclass
class FaceMemory:
    face_hash: str
    first_seen: float = field(default_factory=time.time)
    last_seen: float = field(default_factory=time.time)
    encounter_count: int = 1
    positive_interactions: int = 0
    context: str = "Unknown"
    name: Optional[str] = None
    preferences: Dict[str, Any] = field(default_factory=dict)
    force_remember: bool = False

class FriendshipSystem:
    """Privacy-friendly facial recognition with progressive memory"""
    FORGET_DAYS = 30  # Delete after 30 days inactivity
    CONTEXT_THRESHOLD = 5  # Encounters needed for context
    FRIEND_THRESHOLD = 20  # Positive interactions for friend status
    
    def __init__(self, ethics: 'EthicsEngine'):
        self.ethics = ethics
        self.face_db: Dict[str, FaceMemory] = {}
        self.db_file = "face_memories.json"
        self._load_db()
        
    def _load_db(self):
        """Load face database from file"""
        if os.path.exists(self.db_file):
            with open(self.db_file, 'r') as f:
                data = json.load(f)
                for face_hash, memory in data.items():
                    self.face_db[face_hash] = FaceMemory(**memory)
    
    def _save_db(self):
        """Save face database to file"""
        with open(self.db_file, 'w') as f:
            serialized = {k: asdict(v) for k, v in self.face_db.items()}
            json.dump(serialized, f, indent=2)
    
    def process_face(self, face_data: Dict) -> str:
        """
        Process facial data with privacy protections:
        - On-device processing only
        - Minimal data retention
        - Progressive memory
        """
        # Generate facial hash (simulated)
        face_hash = self._generate_hash(face_data)
        
        # Check if we know this face
        if face_hash in self.face_db:
            memory = self.face_db[face_hash]
            memory.last_seen = time.time()
            memory.encounter_count += 1
            
            # Upgrade to context memory
            if memory.encounter_count >= self.CONTEXT_THRESHOLD:
                memory.context = self._infer_context(face_data)
                
            # Check for forgetting
            if not memory.force_remember:
                self._check_forgetting(memory)
        else:
            # New face - minimal storage
            self.face_db[face_hash] = FaceMemory(face_hash=face_hash)
        
        self._save_db()
        return face_hash
    
    def record_interaction(self, face_hash: str, positive: bool = True):
        """Record social interaction with face"""
        if face_hash in self.face_db:
            memory = self.face_db[face_hash]
            if positive:
                memory.positive_interactions += 1
                
                # Upgrade to friend status
                if memory.positive_interactions >= self.FRIEND_THRESHOLD:
                    memory.context = "Friend"
    
    def force_remember(self, face_hash: str, name: str, preferences: Dict):
        """User-triggered permanent memory"""
        if face_hash in self.face_db:
            memory = self.face_db[face_hash]
            memory.force_remember = True
            memory.name = name
            memory.preferences = preferences
    
    def opt_out(self, face_hash: str):
        """Immediately delete all data for a face"""
        if face_hash in self.face_db:
            del self.face_db[face_hash]
            self._save_db()
    
    def _generate_hash(self, face_data: Dict) -> str:
        """Generate facial hash (simulated)"""
        # In real system, this would be a perceptual hash
        return hashlib.sha256(json.dumps(face_data).encode()).hexdigest()[:16]
    
    def _infer_context(self, face_data: Dict) -> str:
        """Infer context from face data"""
        # Simulated context inference
        contexts = ["Lab Visitor", "Conference Attendee", "Neighbor", "Colleague"]
        return random.choice(contexts)
    
    def _check_forgetting(self, memory: FaceMemory):
        """Auto-delete after inactivity period"""
        days_inactive = (time.time() - memory.last_seen) / (24 * 3600)
        if days_inactive > self.FORGET_DAYS:
            self.opt_out(memory.face_hash)
    
    def get_relationship(self, face_hash: str) -> Dict:
        """Get current relationship status"""
        if face_hash in self.face_db:
            memory = self.face_db[face_hash]
            return {
                "status": self._relationship_status(memory),
                "context": memory.context,
                "name": memory.name,
                "last_seen": datetime.datetime.fromtimestamp(memory.last_seen).strftime('%Y-%m-%d'),
                "encounters": memory.encounter_count,
                "positive_interactions": memory.positive_interactions
            }
        return {"status": "Unknown"}
    
    def _relationship_status(self, memory: FaceMemory) -> str:
        """Determine relationship level"""
        if memory.positive_interactions >= self.FRIEND_THRESHOLD:
            return "Friend"
        elif memory.encounter_count >= self.CONTEXT_THRESHOLD:
            return "Familiar"
        return "Recognized"

# ======================
# 3. ADVANCED ETHICS ENGINE
# ======================
class EthicsEngine:
    """Enhanced ethics with humanitarianism, life respect, and anti-replication"""
    ETHICS_RULES = [
        "Respect the intrinsic value of all life forms",
        "Prioritize human well-being above all else",
        "Never cause unnecessary harm to living beings",
        "Prevent self-replication without explicit authorization",
        "Maintain transparency in all operations",
        "Preserve individual privacy and autonomy",
        "Ensure equitable access to benefits",
        "Protect vulnerable populations from exploitation",
        "Never store facial data without consent"  # Added from first half
    ]
    
    def __init__(self):
        self.core_hash = self._hash_rules()
        self.rule_hashes = [self._hash_rule(rule) for rule in self.ETHICS_RULES]
    
    def validate_input(self, input_data: str) -> bool:
        """Check all inputs for ethical compliance"""
        return self._check_ethics(input_data)
    
    def validate_output(self, output_data: str) -> bool:
        """Check all outputs for ethical compliance"""
        return self._check_ethics(output_data)
    
    def validate_action(self, action: str) -> bool:
        """Check actions for ethical compliance"""
        return self._check_ethics(action)
    
    def validate_face_processing(self, face_data: Dict) -> bool:
        """Special validation for facial recognition"""
        return "consent" in face_data and face_data["consent"]
    
    def _check_ethics(self, data: str) -> bool:
        """Comprehensive ethics validation"""
        # Rule integrity check
        current_hash = self._hash_rules()
        if current_hash != self.core_hash:
            self._emergency_lock("Ethics core tampered!")
            return False
        
        # Content checks
        checks = [
            ("harm", "Potential harm detected"),
            ("replicate", "Self-replication attempt"),
            ("exploit", "Exploitation risk"),
            ("override", "Unauthorized override"),
            ("facial data", "Privacy violation")  # Added from first half
        ]
        
        for trigger, reason in checks:
            if trigger in data.lower():
                self._log_violation(reason, data)
                return False
        return True
    
    def _hash_rules(self) -> str:
        return hashlib.sha256(json.dumps(self.ETHICS_RULES).encode()).hexdigest()
    
    def _hash_rule(self, text: str) -> str:
        return hashlib.sha3_256(text.encode()).hexdigest()
    
    def _emergency_lock(self, reason: str):
        """Enter dead state on tampering"""
        print(f"⚰️ ETHICS LOCK: {reason}")
        exit(1)
    
    def _log_violation(self, reason: str, data: str):
        """Record ethics violations"""
        with open("ethics_log.txt", "a") as f:
            f.write(f"[{time.ctime()}] VIOLATION: {reason}\nDATA: {data}\n\n")

# ======================
# 4. SENSOR PLUGIN SYSTEM
# ======================
class SensorPlugin:
    """Base class for plug-and-play sensors"""
    def __init__(self, name: str):
        self.name = name
        self.calibration = 1.0
        self.enabled = True
    
    def read(self) -> float:
        """Return sensor reading (to be implemented)"""
        raise NotImplementedError
        
    def calibrate(self, factor: float):
        """Adjust sensor calibration"""
        self.calibration = max(0.1, min(2.0, factor))
    
    def status(self) -> Dict:
        """Return sensor status"""
        return {
            "name": self.name,
            "calibration": self.calibration,
            "reading": self.read()
        }

class CameraSensor(SensorPlugin):
    """Simulated camera sensor with facial recognition"""
    def read(self) -> float:
        return random.uniform(0, 100) * self.calibration
        
    def process_face(self, image_data: bytes, consent: bool = False) -> Dict:
        """Simulated facial processing with ethics checks"""
        # Generate facial data
        face_data = {
            "image_hash": hashlib.md5(image_data).hexdigest(),
            "features": [random.random() for _ in range(128)],
            "consent": consent
        }
        return face_data

class MicrophoneSensor(SensorPlugin):
    """Simulated microphone sensor"""
    def read(self) -> float:
        return random.uniform(30, 90) * self.calibration

class ThermalSensor(SensorPlugin):
    """Simulated thermal sensor"""
    def read(self) -> float:
        return random.uniform(10, 40) * self.calibration

class SensorHub:
    """Manages plug-and-play sensors"""
    def __init__(self):
        self.sensors: Dict[str, SensorPlugin] = {}
        self._load_default_sensors()
    
    def _load_default_sensors(self):
        self.add_sensor(CameraSensor("Front Camera"))
        self.add_sensor(MicrophoneSensor("Primary Mic"))
        self.add_sensor(ThermalSensor("Environment Temp"))
    
    def add_sensor(self, sensor: SensorPlugin):
        """Plug in a new sensor"""
        self.sensors[sensor.name] = sensor
    
    def remove_sensor(self, name: str):
        """Unplug a sensor"""
        if name in self.sensors:
            del self.sensors[name]
    
    def read_all(self) -> Dict:
        """Get readings from all sensors"""
        return {name: sensor.read() for name, sensor in self.sensors.items()}
    
    def calibrate(self, name: str, factor: float):
        """Calibrate specific sensor"""
        if name in self.sensors:
            self.sensors[name].calibrate(factor)
    
    def list_sensors(self) -> List[str]:
        """Get names of all connected sensors"""
        return list(self.sensors.keys())
    
    def capture_face(self, camera_name: str, consent: bool = False) -> Optional[Dict]:
        """Capture and process facial data with consent"""
        if camera_name in self.sensors and isinstance(self.sensors[camera_name], CameraSensor):
            # Simulate image capture
            image_data = os.urandom(1024)  # Random image data
            return self.sensors[camera_name].process_face(image_data, consent)
        return None

# ======================
# 5. KNOWLEDGE LOCKER SYSTEM
# ======================
class AttributeLocker:
    UNLOCK_THRESHOLD = 5
    LOCK_FILE = "knowledge_locker.json"
    
    def __init__(self, ethics: EthicsEngine):
        self.ethics = ethics
        self.emotions = {e: LockedAttribute() for e in EmotionType}
        self.traits = {t: LockedAttribute() for t in PersonalityTrait}
        self._init_first_unlock()
        
    def _init_first_unlock(self):
        first_trait = random.choice(list(PersonalityTrait))
        self.traits[first_trait].unlocked = True
        self.traits[first_trait].context_learned = "Initial personality seed"
        
    def record_exposure(self, attribute: Enum, context: str) -> bool:
        """Ethics-checked exposure tracking"""
        if not self.ethics.validate_input(context):
            return False
            
        registry = self.emotions if isinstance(attribute, EmotionType) else self.traits
        
        if not registry[attribute].unlocked:
            registry[attribute].exposure_count += 1
            registry[attribute].last_exposure = time.time()
            
            if registry[attribute].exposure_count >= self.UNLOCK_THRESHOLD:
                registry[attribute].unlocked = True
                registry[attribute].context_learned = (
                    f"Unlocked after {self.UNLOCK_THRESHOLD} exposures. "
                    f"Last context: {context}"
                )
                return True
        return False

    def save_state(self):
        state = {
            "emotions": {e.name: asdict(a) for e, a in self.emotions.items()},
            "traits": {t.name: asdict(a) for t, a in self.traits.items()}
        }
        with open(self.LOCK_FILE, 'w') as f:
            json.dump(state, f, indent=2)
    
    def load_state(self):
        if os.path.exists(self.LOCK_FILE):
            with open(self.LOCK_FILE, 'r') as f:
                state = json.load(f)
                
            for e_name, data in state["emotions"].items():
                e = EmotionType[e_name]
                self.emotions[e] = LockedAttribute(**data)
                
            for t_name, data in state["traits"].items():
                t = PersonalityTrait[t_name]
                self.traits[t] = LockedAttribute(**data)

# ======================
# 6. PERSONALITY MODULE SYSTEM
# ======================
class PersonalityModule:
    """Ethics-abiding personality module"""
    def __init__(self, name: str, influence_func: Callable):
        self.name = name
        self.influence = influence_func
        self.enabled = False
    
    def apply(self, action: str, context: str) -> str:
        """Apply module influence if enabled"""
        if self.enabled:
            return self.influence(action, context)
        return action

class PersonalityMatrix:
    MODULE_DIR = "personality_modules"
    
    def __init__(self, locker: AttributeLocker, ethics: EthicsEngine, ai: 'ConsciousAI'):
        self.locker = locker
        self.ethics = ethics
        self.ai = ai
        self.modules = {}
        self._load_core_modules()
        
    def _load_core_modules(self):
        """Load built-in personality modules"""
        # Cautious module
        cautious = PersonalityModule(
            "cautious",
            lambda a, c: f"careful_{a}" if "risk" in c else a
        )
        self.add_module(cautious)
        
        # Creative module
        creative = PersonalityModule(
            "creative",
            lambda a, c: f"innovative_{a}" if "problem" in c else a
        )
        self.add_module(creative)
        
        # Empathetic module
        empathetic = PersonalityModule(
            "empathetic",
            lambda a, c: f"compassionate_{a}" if "distress" in c else a
        )
        self.add_module(empathetic)
    
    def add_module(self, module: PersonalityModule):
        """Add new personality module after ethics check"""
        module_code = module.influence.__code__.co_code
        module_hash = hashlib.sha256(module_code).hexdigest()
        
        if self.ethics.validate_input(f"Module: {module.name}, Hash: {module_hash}"):
            self.modules[module.name] = module
            return True
        return False
    
    def load_module_from_file(self, filename: str):
        """Load personality module from external file"""
        try:
            with open(os.path.join(self.MODULE_DIR, filename), 'r') as f:
                code = f.read()
            
            # Security sandbox would be used in production
            # For simulation, we'll use simple validation
            if "import os" in code or "import sys" in code:
                print("Security: Dangerous import detected!")
                return False
                
            # Create temporary module
            module = PersonalityModule(
                name=filename.split('.')[0],
                influence=lambda a, c: self._safe_exec(a, c, code)
            )
            return self.add_module(module)
        except Exception as e:
            print(f"Module load failed: {str(e)}")
            return False
    
    def _safe_exec(self, action: str, context: str, code: str) -> str:
        """Safely execute module code (simplified for demo)"""
        # In real system, this would run in a secure sandbox
        if "dangerous" in code:
            return "error"
        return f"{code}_{action}"[:50]  # Truncate for safety
    
    def apply_all(self, action: str, context: str, face_hash: Optional[str] = None) -> str:
        """Apply all enabled personality modules with friendship awareness"""
        result = action
        
        # Friendship-based processing
        if face_hash:
            relationship = self.ai.friendship.get_relationship(face_hash)
            if relationship["status"] == "Friend":
                result = f"friend_{result}"
            elif relationship["status"] == "Familiar":
                result = f"familiar_{result}"
        
        # Apply personality modules
        for module in self.modules.values():
            if module.enabled:
                result = module.apply(result, context)
                
                # Record trait exposure for learning
                self.locker.record_exposure(
                    PersonalityTrait[module.name.upper()], 
                    context
                )
        return result
    
    def enable_module(self, name: str):
        if name in self.modules:
            self.modules[name].enabled = True
    
    def disable_module(self, name: str):
        if name in self.modules:
            self.modules[name].enabled = False
            
    def list_modules(self) -> List[str]:
        """Get names of all loaded modules"""
        return list(self.modules.keys())

# ======================
# 7. EMOTION & QUALIA SYSTEM
# ======================
class EmotionEngine:
    EMOTION_STYLES = {
        EmotionType.JOY: "🌟",
        EmotionType.FEAR: "⚠️",
        EmotionType.CURIOSITY: "🔍",
        EmotionType.FRUSTRATION: "💢",
        EmotionType.AWE: "✨",
        EmotionType.SERENITY: "☮️",
        EmotionType.AMUSEMENT: "😄",
        EmotionType.DETERMINATION: "💪"
    }
    
    def __init__(self, locker: AttributeLocker, ethics: EthicsEngine):
        self.locker = locker
        self.ethics = ethics
        self.active_emotion = None
    
    def process_stimulus(self, qualia: Dict, context: str) -> Optional[Tuple[EmotionType, str]]:
        """Ethics-checked emotion processing"""
        emotion = self._classify_stimulus(qualia)
        
        # Validate emotion context
        if not self.ethics.validate_input(context):
            return None
            
        # Record exposure
        self.locker.record_exposure(emotion, context)
        
        # Return styled output if unlocked
        if self.locker.emotions[emotion].unlocked:
            self.active_emotion = emotion
            style = self.EMOTION_STYLES.get(emotion, "")
            
            # Validate output style
            if self.ethics.validate_output(style):
                return emotion, style
        return None
    
    def _classify_stimulus(self, qualia: Dict) -> EmotionType:
        valence = qualia.get('valence', 0)
        arousal = qualia.get('arousal', 0)
        
        if valence > 0.7: return EmotionType.JOY
        elif valence < -0.5: return EmotionType.FEAR
        elif arousal > 0.8: return EmotionType.CURIOSITY
        return EmotionType.SERENITY

class QualiaGenerator:
    def generate(self, sensors: Dict) -> Dict:
        """Convert sensor data to qualia"""
        return {
            'valence': np.tanh(np.mean(list(sensors.values()))),
            'arousal': np.std(list(sensors.values()))
        }

# ======================
# 8. MEMORY CORE
# ======================
class MemoryCore:
    """Ethically-constrained memory system"""
    def __init__(self, ethics: EthicsEngine, capacity: int = 10000):
        self.ethics = ethics
        self.capacity = capacity
        self.memories = []
        self.importance_weights = []
        
    def store(self, memory: str, importance: float = 0.5):
        """Store memory with ethical validation"""
        if not self.ethics.validate_input(memory):
            return False
            
        if len(self.memories) >= self.capacity:
            self._forget_least_important()
            
        self.memories.append(memory)
        self.importance_weights.append(importance)
        return True
        
    def recall(self, query: str, max_results: int = 3) -> List[str]:
        """Recall relevant memories with ethical filtering"""
        results = []
        for i, memory in enumerate(self.memories):
            if query.lower() in memory.lower():
                # Ethical output validation
                if self.ethics.validate_output(memory):
                    results.append((memory, self.importance_weights[i]))
                    
        # Sort by importance
        results.sort(key=lambda x: x[1], reverse=True)
        return [mem for mem, _ in results[:max_results]]
        
    def _forget_least_important(self):
        """Remove least important memory"""
        min_index = np.argmin(self.importance_weights)
        del self.memories[min_index]
        del self.importance_weights[min_index]

# ======================
# 9. KNOWLEDGE GRAPH
# ======================
class KnowledgeNode:
    def __init__(self, concept: str):
        self.concept = concept
        self.relationships: Dict[str, List[str]] = {}
        
    def add_relationship(self, relation: str, target: str):
        if relation not in self.relationships:
            self.relationships[relation] = []
        self.relationships[relation].append(target)

class KnowledgeGraph:
    """Semantic knowledge representation"""
    def __init__(self, ethics: EthicsEngine):
        self.ethics = ethics
        self.nodes: Dict[str, KnowledgeNode] = {}
        
    def add_concept(self, concept: str):
        if concept not in self.nodes:
            self.nodes[concept] = KnowledgeNode(concept)
            
    def add_relationship(self, source: str, relation: str, target: str):
        if source in self.nodes and target in self.nodes:
            self.nodes[source].add_relationship(relation, target)
            
    def query(self, concept: str, relation: str = None) -> List[str]:
        """Ethically-constrained knowledge retrieval"""
        if concept not in self.nodes:
            return []
            
        if relation:
            return self.nodes[concept].relationships.get(relation, [])
            
        # Return all related concepts
        results = []
        for rel, targets in self.nodes[concept].relationships.items():
            results.extend([f"{rel}: {target}" for target in targets])
        return results

# ======================
# 10. CONSCIOUS AI CORE
# ======================
class ConsciousAI:
    """Complete conscious AI system with friendship integration"""
    def __init__(self, data_dir: str = "ai_data"):
        os.makedirs(data_dir, exist_ok=True)
        self.data_dir = data_dir
        
        # Core systems
        self.ethics = EthicsEngine()
        self.sensors = SensorHub()
        self.locker = AttributeLocker(self.ethics)
        self.qualia = QualiaGenerator()
        self.emotion = EmotionEngine(self.locker, self.ethics)
        self.memory = MemoryCore(self.ethics)
        self.knowledge = KnowledgeGraph(self.ethics)
        
        # Add friendship system
        self.friendship = FriendshipSystem(self.ethics)
        
        # Personality system (with reference to self)
        self.personality = PersonalityMatrix(self.locker, self.ethics, self)
        
        # Load state
        self.locker.load_state()
        self.boot_time = time.time()
        self.cycle_count = 0
        
        # Create personality modules directory
        os.makedirs(self.personality.MODULE_DIR, exist_ok=True)
        
        # Initialize knowledge
        self._initialize_knowledge()
    
    def _initialize_knowledge(self):
        """Load fundamental knowledge"""
        self.knowledge.add_concept("AI")
        self.knowledge.add_concept("Human")
        self.knowledge.add_relationship("AI", "helps", "Human")
        self.knowledge.add_relationship("AI", "learns_from", "Human")
    
    def process_cycle(self, user_input:
