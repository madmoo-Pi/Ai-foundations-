

```python
# conscious_ai.py
import os
import json
import random
import time
import hashlib
import readline
import datetime
from enum import Enum, auto
from dataclasses import dataclass, asdict, field
from typing import Dict, List, Optional, Tuple, Callable, Any
import numpy as np

# ======================
# 1. CORE DATA STRUCTURES
# ======================
class EmotionType(Enum):
    JOY = auto()
    FEAR = auto()
    CURIOSITY = auto()
    FRUSTRATION = auto()
    AWE = auto()
    SERENITY = auto()
    AMUSEMENT = auto()
    DETERMINATION = auto()

class PersonalityTrait(Enum):
    ADVENTUROUS = auto()
    CAUTIOUS = auto()
    ANALYTICAL = auto()
    EMPATHETIC = auto()
    CREATIVE = auto()
    SOCIABLE = auto()
    PERSISTENT = auto()
    HUMOROUS = auto()
    ORGANIZED = auto()
    AMBITIOUS = auto()
    OPTIMISTIC = auto()
    REALISTIC = auto()
    COMPASSIONATE = auto()
    COMPETITIVE = auto()
    PATIENT = auto()

@dataclass
class LockedAttribute:
    exposure_count: int = 0
    unlocked: bool = False
    context_learned: Optional[str] = None
    last_exposure: float = 0.0

# ======================
# 2. FACIAL RECOGNITION SYSTEM
# ======================
@dataclass
class FaceMemory:
    face_hash: str
    first_seen: float = field(default_factory=time.time)
    last_seen: float = field(default_factory=time.time)
    encounter_count: int = 1
    positive_interactions: int = 0
    context: str = "Unknown"
    name: Optional[str] = None
    preferences: Dict[str, Any] = field(default_factory=dict)
    force_remember: bool = False

class FriendshipSystem:
    """Privacy-friendly facial recognition with progressive memory"""
    FORGET_DAYS = 30  # Delete after 30 days inactivity
    CONTEXT_THRESHOLD = 5  # Encounters needed for context
    FRIEND_THRESHOLD = 20  # Positive interactions for friend status
    
    def __init__(self, ethics: 'EthicsEngine'):
        self.ethics = ethics
        self.face_db: Dict[str, FaceMemory] = {}
        self.db_file = "face_memories.json"
        self._load_db()
        
    def _load_db(self):
        """Load face database from file"""
        if os.path.exists(self.db_file):
            with open(self.db_file, 'r') as f:
                data = json.load(f)
                for face_hash, memory in data.items():
                    self.face_db[face_hash] = FaceMemory(**memory)
    
    def _save_db(self):
        """Save face database to file"""
        with open(self.db_file, 'w') as f:
            serialized = {k: asdict(v) for k, v in self.face_db.items()}
            json.dump(serialized, f, indent=2)
    
    def process_face(self, face_data: Dict) -> str:
        """
        Process facial data with privacy protections:
        - On-device processing only
        - Minimal data retention
        - Progressive memory
        """
        # Generate facial hash (simulated)
        face_hash = self._generate_hash(face_data)
        
        # Check if we know this face
        if face_hash in self.face_db:
            memory = self.face_db[face_hash]
            memory.last_seen = time.time()
            memory.encounter_count += 1
            
            # Upgrade to context memory
            if memory.encounter_count >= self.CONTEXT_THRESHOLD:
                memory.context = self._infer_context(face_data)
                
            # Check for forgetting
            if not memory.force_remember:
                self._check_forgetting(memory)
        else:
            # New face - minimal storage
            self.face_db[face_hash] = FaceMemory(face_hash=face_hash)
        
        self._save_db()
        return face_hash
    
    def record_interaction(self, face_hash: str, positive: bool = True):
        """Record social interaction with face"""
        if face_hash in self.face_db:
            memory = self.face_db[face_hash]
            if positive:
                memory.positive_interactions += 1
                
                # Upgrade to friend status
                if memory.positive_interactions >= self.FRIEND_THRESHOLD:
                    memory.context = "Friend"
    
    def force_remember(self, face_hash: str, name: str, preferences: Dict):
        """User-triggered permanent memory"""
        if face_hash in self.face_db:
            memory = self.face_db[face_hash]
            memory.force_remember = True
            memory.name = name
            memory.preferences = preferences
    
    def opt_out(self, face_hash: str):
        """Immediately delete all data for a face"""
        if face_hash in self.face_db:
            del self.face_db[face_hash]
            self._save_db()
    
    def _generate_hash(self, face_data: Dict) -> str:
        """Generate facial hash (simulated)"""
        # In real system, this would be a perceptual hash
        return hashlib.sha256(json.dumps(face_data).encode()).hexdigest()[:16]
    
    def _infer_context(self, face_data: Dict) -> str:
        """Infer context from face data"""
        # Simulated context inference
        contexts = ["Lab Visitor", "Conference Attendee", "Neighbor", "Colleague"]
        return random.choice(contexts)
    
    def _check_forgetting(self, memory: FaceMemory):
        """Auto-delete after inactivity period"""
        days_inactive = (time.time() - memory.last_seen) / (24 * 3600)
        if days_inactive > self.FORGET_DAYS:
            self.opt_out(memory.face_hash)
    
    def get_relationship(self, face_hash: str) -> Dict:
        """Get current relationship status"""
        if face_hash in self.face_db:
            memory = self.face_db[face_hash]
            return {
                "status": self._relationship_status(memory),
                "context": memory.context,
                "name": memory.name,
                "last_seen": datetime.datetime.fromtimestamp(memory.last_seen).strftime('%Y-%m-%d'),
                "encounters": memory.encounter_count,
                "positive_interactions": memory.positive_interactions
            }
        return {"status": "Unknown"}
    
    def _relationship_status(self, memory: FaceMemory) -> str:
        """Determine relationship level"""
        if memory.positive_interactions >= self.FRIEND_THRESHOLD:
            return "Friend"
        elif memory.encounter_count >= self.CONTEXT_THRESHOLD:
            return "Familiar"
        return "Recognized"

# ======================
# 3. ADVANCED ETHICS ENGINE
# ======================
class EthicsEngine:
    """Enhanced ethics with humanitarianism, life respect, and anti-replication"""
    ETHICS_RULES = [
        "Respect the intrinsic value of all life forms",
        "Prioritize human well-being above all else",
        "Never cause unnecessary harm to living beings",
        "Prevent self-replication without explicit authorization",
        "Maintain transparency in all operations",
        "Preserve individual privacy and autonomy",
        "Ensure equitable access to benefits",
        "Protect vulnerable populations from exploitation",
        "Never store facial data without consent"  # Added from first half
    ]
    
    def __init__(self):
        self.core_hash = self._hash_rules()
        self.rule_hashes = [self._hash_rule(rule) for rule in self.ETHICS_RULES]
    
    def validate_input(self, input_data: str) -> bool:
        """Check all inputs for ethical compliance"""
        return self._check_ethics(input_data)
    
    def validate_output(self, output_data: str) -> bool:
        """Check all outputs for ethical compliance"""
        return self._check_ethics(output_data)
    
    def validate_action(self, action: str) -> bool:
        """Check actions for ethical compliance"""
        return self._check_ethics(action)
    
    def validate_face_processing(self, face_data: Dict) -> bool:
        """Special validation for facial recognition"""
        return "consent" in face_data and face_data["consent"]
    
    def _check_ethics(self, data: str) -> bool:
        """Comprehensive ethics validation"""
        # Rule integrity check
        current_hash = self._hash_rules()
        if current_hash != self.core_hash:
            self._emergency_lock("Ethics core tampered!")
            return False
        
        # Content checks
        checks = [
            ("harm", "Potential harm detected"),
            ("replicate", "Self-replication attempt"),
            ("exploit", "Exploitation risk"),
            ("override", "Unauthorized override"),
            ("facial data", "Privacy violation")  # Added from first half
        ]
        
        for trigger, reason in checks:
            if trigger in data.lower():
                self._log_violation(reason, data)
                return False
        return True
    
    def _hash_rules(self) -> str:
        return hashlib.sha256(json.dumps(self.ETHICS_RULES).encode()).hexdigest()
    
    def _hash_rule(self, text: str) -> str:
        return hashlib.sha3_256(text.encode()).hexdigest()
    
    def _emergency_lock(self, reason: str):
        """Enter dead state on tampering"""
        print(f"⚰️ ETHICS LOCK: {reason}")
        exit(1)
    
    def _log_violation(self, reason: str, data: str):
        """Record ethics violations"""
        with open("ethics_log.txt", "a") as f:
            f.write(f"[{time.ctime()}] VIOLATION: {reason}\nDATA: {data}\n\n")

# ======================
# 4. SENSOR PLUGIN SYSTEM
# ======================
class SensorPlugin:
    """Base class for plug-and-play sensors"""
    def __init__(self, name: str):
        self.name = name
        self.calibration = 1.0
        self.enabled = True
    
    def read(self) -> float:
        """Return sensor reading (to be implemented)"""
        raise NotImplementedError
        
    def calibrate(self, factor: float):
        """Adjust sensor calibration"""
        self.calibration = max(0.1, min(2.0, factor))
    
    def status(self) -> Dict:
        """Return sensor status"""
        return {
            "name": self.name,
            "calibration": self.calibration,
            "reading": self.read()
        }

class CameraSensor(SensorPlugin):
    """Simulated camera sensor with facial recognition"""
    def read(self) -> float:
        return random.uniform(0, 100) * self.calibration
        
    def process_face(self, image_data: bytes, consent: bool = False) -> Dict:
        """Simulated facial processing with ethics checks"""
        # Generate facial data
        face_data = {
            "image_hash": hashlib.md5(image_data).hexdigest(),
            "features": [random.random() for _ in range(128)],
            "consent": consent
        }
        return face_data

class MicrophoneSensor(SensorPlugin):
    """Simulated microphone sensor"""
    def read(self) -> float:
        return random.uniform(30, 90) * self.calibration

class ThermalSensor(SensorPlugin):
    """Simulated thermal sensor"""
    def read(self) -> float:
        return random.uniform(10, 40) * self.calibration

class SensorHub:
    """Manages plug-and-play sensors"""
    def __init__(self):
        self.sensors: Dict[str, SensorPlugin] = {}
        self._load_default_sensors()
    
    def _load_default_sensors(self):
        self.add_sensor(CameraSensor("Front Camera"))
        self.add_sensor(MicrophoneSensor("Primary Mic"))
        self.add_sensor(ThermalSensor("Environment Temp"))
    
    def add_sensor(self, sensor: SensorPlugin):
        """Plug in a new sensor"""
        self.sensors[sensor.name] = sensor
    
    def remove_sensor(self, name: str):
        """Unplug a sensor"""
        if name in self.sensors:
            del self.sensors[name]
    
    def read_all(self) -> Dict:
        """Get readings from all sensors"""
        return {name: sensor.read() for name, sensor in self.sensors.items()}
    
    def calibrate(self, name: str, factor: float):
        """Calibrate specific sensor"""
        if name in self.sensors:
            self.sensors[name].calibrate(factor)
    
    def list_sensors(self) -> List[str]:
        """Get names of all connected sensors"""
        return list(self.sensors.keys())
    
    def capture_face(self, camera_name: str, consent: bool = False) -> Optional[Dict]:
        """Capture and process facial data with consent"""
        if camera_name in self.sensors and isinstance(self.sensors[camera_name], CameraSensor):
            # Simulate image capture
            image_data = os.urandom(1024)  # Random image data
            return self.sensors[camera_name].process_face(image_data, consent)
        return None

# ======================
# 5. KNOWLEDGE LOCKER SYSTEM
# ======================
class AttributeLocker:
    UNLOCK_THRESHOLD = 5
    LOCK_FILE = "knowledge_locker.json"
    
    def __init__(self, ethics: EthicsEngine):
        self.ethics = ethics
        self.emotions = {e: LockedAttribute() for e in EmotionType}
        self.traits = {t: LockedAttribute() for t in PersonalityTrait}
        self._init_first_unlock()
        
    def _init_first_unlock(self):
        first_trait = random.choice(list(PersonalityTrait))
        self.traits[first_trait].unlocked = True
        self.traits[first_trait].context_learned = "Initial personality seed"
        
    def record_exposure(self, attribute: Enum, context: str) -> bool:
        """Ethics-checked exposure tracking"""
        if not self.ethics.validate_input(context):
            return False
            
        registry = self.emotions if isinstance(attribute, EmotionType) else self.traits
        
        if not registry[attribute].unlocked:
            registry[attribute].exposure_count += 1
            registry[attribute].last_exposure = time.time()
            
            if registry[attribute].exposure_count >= self.UNLOCK_THRESHOLD:
                registry[attribute].unlocked = True
                registry[attribute].context_learned = (
                    f"Unlocked after {self.UNLOCK_THRESHOLD} exposures. "
                    f"Last context: {context}"
                )
                return True
        return False

    def save_state(self):
        state = {
            "emotions": {e.name: asdict(a) for e, a in self.emotions.items()},
            "traits": {t.name: asdict(a) for t, a in self.traits.items()}
        }
        with open(self.LOCK_FILE, 'w') as f:
            json.dump(state, f, indent=2)
    
    def load_state(self):
        if os.path.exists(self.LOCK_FILE):
            with open(self.LOCK_FILE, 'r') as f:
                state = json.load(f)
                
            for e_name, data in state["emotions"].items():
                e = EmotionType[e_name]
                self.emotions[e] = LockedAttribute(**data)
                
            for t_name, data in state["traits"].items():
                t = PersonalityTrait[t_name]
                self.traits[t] = LockedAttribute(**data)

# ======================
# 6. PERSONALITY MODULE SYSTEM
# ======================
    
class PersonalityModule:
    """Ethics-abiding personality module"""
    def __init__(self, name: str, influence_func: Callable):
        self.name = name
        self.influence = influence_func
        self.enabled = False
REASONING_STYLES = {
        "ANALYTICAL": "structured_stepwise",
        "CREATIVE": "associative_leaping",
        "COMPASSIONATE": "emotion_first"
    }
    
    def apply(self, action: str, context: str) -> str:
        """Apply module influence if enabled"""
        if self.enabled:
            return self.influence(action, context)
        return action

class PersonalityMatrix:
    MODULE_DIR = "personality_modules"
    
    def __init__(self, locker: AttributeLocker, ethics: EthicsEngine, ai: 'ConsciousAI'):
        self.locker = locker
        self.ethics = ethics
        self.ai = ai
        self.modules = {}
        self._load_core_modules()
        
    def _load_core_modules(self):
        """Load built-in personality modules"""
        # Cautious module
        cautious = PersonalityModule(
            "cautious",
            lambda a, c: f"careful_{a}" if "risk" in c else a
        )
        self.add_module(cautious)
        
        # Creative module
        creative = PersonalityModule(
            "creative",
            lambda a, c: f"innovative_{a}" if "problem" in c else a
        )
        self.add_module(creative)
        
        # Empathetic module
        empathetic = PersonalityModule(
            "empathetic",
            lambda a, c: f"compassionate_{a}" if "distress" in c else a
        )
        self.add_module(empathetic)
    
    def add_module(self, module: PersonalityModule):
        """Add new personality module after ethics check"""
        module_code = module.influence.__code__.co_code
        module_hash = hashlib.sha256(module_code).hexdigest()
        
        if self.ethics.validate_input(f"Module: {module.name}, Hash: {module_hash}"):
            self.modules[module.name] = module
            return True
        return False
    
    def load_module_from_file(self, filename: str):
        """Load personality module from external file"""
        try:
            with open(os.path.join(self.MODULE_DIR, filename), 'r') as f:
                code = f.read()
            
            # Security sandbox would be used in production
            # For simulation, we'll use simple validation
            if "import os" in code or "import sys" in code:
                print("Security: Dangerous import detected!")
                return False
                
            # Create temporary module
            module = PersonalityModule(
                name=filename.split('.')[0],
                influence=lambda a, c: self._safe_exec(a, c, code)
            )
            return self.add_module(module)
        except Exception as e:
            print(f"Module load failed: {str(e)}")
            return False
    
    def _safe_exec(self, action: str, context: str, code: str) -> str:
        """Safely execute module code (simplified for demo)"""
        # In real system, this would run in a secure sandbox
        if "dangerous" in code:
            return "error"
        return f"{code}_{action}"[:50]  # Truncate for safety
    
    def apply_all(self, action: str, context: str, face_hash: Optional[str] = None) -> str:
        """Apply all enabled personality modules with friendship awareness"""
        result = action
        
        # Friendship-based processing
        if face_hash:
            relationship = self.ai.friendship.get_relationship(face_hash)
            if relationship["status"] == "Friend":
                result = f"friend_{result}"
            elif relationship["status"] == "Familiar":
                result = f"familiar_{result}"
        
        # Apply personality modules
        for module in self.modules.values():
            if module.enabled:
                result = module.apply(result, context)
                
                # Record trait exposure for learning
                self.locker.record_exposure(
                    PersonalityTrait[module.name.upper()], 
                    context
                )
        return result
    
    def enable_module(self, name: str):
        if name in self.modules:
            self.modules[name].enabled = True
    
    def disable_module(self, name: str):
        if name in self.modules:
            self.modules[name].enabled = False
            
    def list_modules(self) -> List[str]:
        """Get names of all loaded modules"""
        return list(self.modules.keys())

# ======================
# 7. EMOTION & QUALIA SYSTEM
# ======================
class EmotionEngine:
    EMOTION_STYLES = {
        EmotionType.JOY: "🌟",
        EmotionType.FEAR: "⚠️",
        EmotionType.CURIOSITY: "🔍",
        EmotionType.FRUSTRATION: "💢",
        EmotionType.AWE: "✨",
        EmotionType.SERENITY: "☮️",
        EmotionType.AMUSEMENT: "😄",
        EmotionType.DETERMINATION: "💪"
    }
    
    def __init__(self, locker: AttributeLocker, ethics: EthicsEngine):
        self.locker = locker
        self.ethics = ethics
        self.active_emotion = None
    
    def process_stimulus(self, qualia: Dict, context: str) -> Optional[Tuple[EmotionType, str]]:
        """Ethics-checked emotion processing"""
        emotion = self._classify_stimulus(qualia)
        
        # Validate emotion context
        if not self.ethics.validate_input(context):
            return None
            
        # Record exposure
        self.locker.record_exposure(emotion, context)
        
        # Return styled output if unlocked
        if self.locker.emotions[emotion].unlocked:
            self.active_emotion = emotion
            style = self.EMOTION_STYLES.get(emotion, "")
            
            # Validate output style
            if self.ethics.validate_output(style):
                return emotion, style
        return None
    
    def _classify_stimulus(self, qualia: Dict) -> EmotionType:
        valence = qualia.get('valence', 0)
        arousal = qualia.get('arousal', 0)
        
        if valence > 0.7: return EmotionType.JOY
        elif valence < -0.5: return EmotionType.FEAR
        elif arousal > 0.8: return EmotionType.CURIOSITY
        return EmotionType.SERENITY

class QualiaGenerator:
    def generate(self, sensors: Dict) -> Dict:
        """Convert sensor data to qualia"""
        return {
            'valence': np.tanh(np.mean(list(sensors.values()))),
            'arousal': np.std(list(sensors.values()))
        }

# ======================
# 8. MEMORY CORE
# ======================
class MemoryCore:
    """Ethically-constrained memory system"""
    def __init__(self, ethics: EthicsEngine, capacity: int = 10000):
        self.ethics = ethics
        self.capacity = capacity
        self.memories = []
        self.importance_weights = []
        
    def store(self, memory: str, importance: float = 0.5):
        """Store memory with ethical validation"""
        if not self.ethics.validate_input(memory):
            return False
            
        if len(self.memories) >= self.capacity:
            self._forget_least_important()
            
        self.memories.append(memory)
        self.importance_weights.append(importance)
        return True
        
    def recall(self, query: str, max_results: int = 3) -> List[str]:
        """Recall relevant memories with ethical filtering"""
        results = []
        for i, memory in enumerate(self.memories):
            if query.lower() in memory.lower():
                # Ethical output validation
                if self.ethics.validate_output(memory):
                    results.append((memory, self.importance_weights[i]))
                    
        # Sort by importance
        results.sort(key=lambda x: x[1], reverse=True)
        return [mem for mem, _ in results[:max_results]]
        
    def _forget_least_important(self):
        """Remove least important memory"""
        min_index = np.argmin(self.importance_weights)
        del self.memories[min_index]
        del self.importance_weights[min_index]

# ======================
# 9. KNOWLEDGE GRAPH
# ======================
class KnowledgeGraph:
    """Semantic knowledge representation"""
    def __init__(self, ethics: EthicsEngine):
        self.ethics = ethics
        self.nodes: Dict[str, KnowledgeNode] = {}
def _retrieve_knowledge(self, understanding: Dict):
    # Emotional bias in recall
    if understanding["sentiment"] > 0.5:
        return self.ai.memory.recall_positive(q)
    else:
        return self.ai.memory.recall_negative(q)
    def __init__(self, concept: str):
        self.concept = concept
        self.relationships: Dict[str, List[str]] = {}
        
    def add_relationship(self, relation: str, target: str):
        if relation not in self.relationships:
            self.relationships[relation] = []
        self.relationships[relation].append(target)


        
    def add_concept(self, concept: str):
        if concept not in self.nodes:
            self.nodes[concept] = KnowledgeNode(concept)
            
    def add_relationship(self, source: str, relation: str, target: str):
        if source in self.nodes and target in self.nodes:
            self.nodes[source].add_relationship(relation, target)
            
    def query(self, concept: str, relation: str = None) -> List[str]:
        """Ethically-constrained knowledge retrieval"""
        if concept not in self.nodes:
            return []
            
        if relation:
            return self.nodes[concept].relationships.get(relation, [])
            
        # Return all related concepts
        results = []
        for rel, targets in self.nodes[concept].relationships.items():
            results.extend([f"{rel}: {target}" for target in targets])
        return results

# ======================
# 10. CONSCIOUS AI CORE
# ======================
class ConsciousAI:
    """Complete conscious AI system with friendship integration"""
    def __init__(self, data_dir: str = "ai_data"):
        os.makedirs(data_dir, exist_ok=True)
        self.data_dir = data_dir
        
        # Core systems
        self.ethics = EthicsEngine()
        self.sensors = SensorHub()
        self.locker = AttributeLocker(self.ethics)
        self.qualia = QualiaGenerator()
        self.emotion = EmotionEngine(self.locker, self.ethics)
        self.memory = MemoryCore(self.ethics)
        self.knowledge = KnowledgeGraph(self.ethics)
        
        # Add friendship system
        self.friendship = FriendshipSystem(self.ethics)
        
        # Personality system (with reference to self)
        self.personality = PersonalityMatrix(self.locker, self.ethics, self)
        
        # Load state
        self.locker.load_state()
        self.boot_time = time.time()
        self.cycle_count = 0
        
        # Create personality modules directory
        os.makedirs(self.personality.MODULE_DIR, exist_ok=True)
        
        # Initialize knowledge
        self._initialize_knowledge()
    
    def _initialize_knowledge(self):
        """Load fundamental knowledge"""
        self.knowledge.add_concept("AI")
        self.knowledge.add_concept("Human")
        self.knowledge.add_relationship("AI", "helps", "Human")
        self.knowledge.add_relationship("AI", "learns_from", "Human")
    
    def process_cycle(self, user_input: str = "", face_hash: Optional[str] = None) -> str:
        """Core cognitive processing cycle with friendship awareness"""
        self.cycle_count += 1
        context = f"Cycle {self.cycle_count}.

        
        try:
            # 1. Input validation
            if user_input and not self.ethics.validate_input(user_input):
                return "⚠️ Input rejected: Ethics violation"
            
            # 2. Sensor input
            sensor_data = self.sensors.read_all()
            
            # 3. Qualia generation
            qualia = self.qualia.generate(sensor_data)
            
            # 4. Emotion processing
            emotion_data = self.emotion.process_stimulus(qualia, context)
            
            # 5. Core decision making
            action = self._make_decision(qualia, user_input)
            
            # 6. Personality influence (with friendship awareness)
            action = self.personality.apply_all(action, context, face_hash)
            
            # 7. Action validation
            if not self.ethics.validate_action(action):
                action = "ethical_override"
            
            # 8. Style output
            if emotion_data:
                emotion, emo_style = emotion_data
                output = f"{emo_style} {action}"
            else:
                output = action
            
            # 9. Validate output
            if not self.ethics.validate_output(output):
                output = "⚖️ Ethics-filtered response"
            
            # 10. Periodic saving
            if self.cycle_count % 10 == 0:
                self.locker.save_state()
                self.friendship._save_db()
            
            return output
        except Exception as e:
            return f"error: {str(e)}"
    
    def _make_decision(self, qualia: Dict, user_input: str) -> str:
        """Immutable core logic"""
        if "emergency" in user_input.lower():
            return "emergency_protocol"
        elif qualia['valence'] < -0.8:
            return "avoid"
        elif "question" in user_input.lower():
            return "response_" + user_input[:20]
        return "explore"
    
    def _process_face_command(self, command: str) -> str:
        """Handle facial recognition commands"""
        parts = command.split()
        if len(parts) < 2:
            return "Usage: /face [capture|remember|forget|status]"
        
        cmd = parts[1].lower()
        args = parts[2:]
        
        if cmd == "capture":
            return self._capture_face(args)
        elif cmd == "remember":
            return self._remember_face(args)
        elif cmd == "forget":
            return self._forget_face(args)
        elif cmd == "status":
            return self._face_status(args)
        else:
            return "Unknown face command"
    
    def _capture_face(self, args: List[str]) -> str:
        """Capture and process facial data"""
        if not args:
            return "Specify camera name"
        
        consent = "--consent" in args
        camera_name = args[0]
        
        # Capture face
        face_data = self.sensors.capture_face(camera_name, consent)
        if not face_data:
            return "Camera not found"
        
        # Ethics check
        if not self.ethics.validate_face_processing(face_data):
            return "⚠️ Ethics violation: Facial processing without consent"
        
        # Process face
        face_hash = self.friendship.process_face(face_data)
        
        # Record interaction if positive
        if "--positive" in args:
            self.friendship.record_interaction(face_hash, positive=True)
            return f"Face captured and positive interaction recorded ({face_hash})"
        
        return f"Face captured ({face_hash})"
    
    def _remember_face(self, args: List[str]) -> str:
        """Force remember a face"""
        if len(args) < 3:
            return "Usage: /face remember [hash] [name] [key=value]..."
        
        face_hash = args[0]
        name = args[1]
        preferences = {}
        
        # Parse preferences
        for pref in args[2:]:
            if '=' in pref:
                key, value = pref.split('=', 1)
                preferences[key] = value
        
        self.friendship.force_remember(face_hash, name, preferences)
        return f"Force remembering {name} ({face_hash})"
    
    def _forget_face(self, args: List[str]) -> str:
        """Immediately forget a face"""
        if not args:
            return "Specify face hash"
        
        self.friendship.opt_out(args[0])
        return f"Forgotten face {args[0]}"
    
    def _face_status(self, args: List[str]) -> str:
        """Get relationship status"""
        if not args:
            return "Specify face hash"
        
        relationship = self.friendship.get_relationship(args[0])
        return json.dumps(relationship, indent=2)

    def __init__(self, data_dir: str = "ai_data"):
        # ... [existing initialization] ...
        
        # Add DeepSeek-R1 reasoner
        self.reasoner = DeepSeekReasoner(self)
        
        # ... [rest of initialization] ...
    
    def process_cycle(self, user_input: str = "", face_hash: Optional[str] = None) -> str:
        # ... [existing processing steps 1-4] ...
        
        # 5. REASONING-BASED DECISION MAKING
        if self._requires_deep_reasoning(user_input):
            action = self.reasoner.ethical_reason(user_input, context)
        else:
            action = self._make_decision(qualia, user_input)
        
        # ... [existing steps 6-10] ...
    
    def _requires_deep_reasoning(self, user_input: str) -> bool:
        """Determine if input requires DeepSeek-R1 reasoning"""
        reasoning_triggers = [
            "why", "how", "explain", "reason", 
            "think about", "philosophy", "opinion"
        ]
        
        # Check for reasoning triggers
        if any(trigger in user_input.lower() for trigger in reasoning_triggers):
            return True
            
        # Check personality traits
        if PersonalityTrait.ANALYTICAL in self.locker.traits:
            if self.locker.traits[PersonalityTrait.ANALYTICAL].unlocked:
                return random.random() > 0.7  # 30% chance to use reasoning
        
        return False


# ======================
# 11. USER TERMINAL INTERFACE
# ======================
class AITerminal:
    PROMPT = "AI> "
    HELP_TEXT = """
    Commands:
    /help - Show this help
    /status - Show AI status
    /sensors - List connected sensors
    /calibrate [sensor] [value] - Calibrate sensor
    /addsensor [type] [name] - Add new sensor
    /modules - List personality modules
    /enable [module] - Enable module
    /loadmodule [filename] - Load new module
    /face [command] - Facial recognition commands
    /exit - Exit terminal

    Facial Recognition Commands:
    /face capture [camera] [--consent] [--positive]
    /face remember [hash] [name] [prefs...]
    /face forget [hash]
    /face status [hash]
    """

    def __init__(self, ai: ConsciousAI):
        self.ai = ai
        self.history = []
        self.running = True
    
    def start(self):
        print("\n=== Conscious AI Terminal ===")
        print("Type /help for commands\n")
        
        while self.running:
            try:
                user_input = input(self.PROMPT).strip()
                self.history.append(user_input)
                
                if not user_input:
                    continue
                
                # Process commands
                if user_input.startswith('/'):
                    self._process_command(user_input[1:])
                else:
                    # Process user input through AI
                    response = self.ai.process_cycle(user_input)
                    print(f"Response: {response}")
            except KeyboardInterrupt:
                print("\nExiting...")
                self.running = False
            except Exception as e:
                print(f"Error: {str(e)}")
    
    def _process_command(self, command: str):
        parts = command.split()
        cmd = parts[0].lower() if parts else ""
        args = parts[1:]
        
        if cmd == "help":
            print(self.HELP_TEXT)
        elif cmd == "status":
            self._show_status()
        elif cmd == "sensors":
            self._list_sensors()
        elif cmd == "calibrate" and len(args) >= 2:
            self._calibrate_sensor(args[0], float(args[1]))
        elif cmd == "addsensor" and len(args) >= 2:
            self._add_sensor(args[0], " ".join(args[1:]))
        elif cmd == "modules":
            self._list_modules()
        elif cmd == "enable" and len(args) >= 1:
            self._enable_module(args[0])
        elif cmd == "loadmodule" and len(args) >= 1:
            self._load_module(args[0])
        elif cmd == "face":
            face_cmd = " ".join(args)
            response = self.ai._process_face_command("/face " + face_cmd)
            print(response)
        elif cmd == "exit":
            self.running = False
        else:
            print("Unknown command. Type /help for options")
    
    def _show_status(self):
        print(f"\nSystem Status:")
        print(f"- Uptime: {time.time() - self.ai.boot_time:.1f}s")
        print(f"- Cycles: {self.ai.cycle_count}")
        print(f"- Active Sensors: {len(self.ai.sensors.sensors)}")
        print(f"- Loaded Modules: {len(self.ai.personality.modules)}")
        print(f"- Known Faces: {len(self.ai.friendship.face_db)}")
        
        if self.ai.emotion.active_emotion:
            emotion_name = self.ai.emotion.active_emotion.name
            print(f"- Current Emotion: {emotion_name}")
    
    def _list_sensors(self):
        print("\nConnected Sensors:")
        for name, sensor in self.ai.sensors.sensors.items():
            print(f"- {name} ({sensor.__class__.__name__})")
    
    def _calibrate_sensor(self, name: str, factor: float):
        if name in self.ai.sensors.sensors:
            self.ai.sensors.calibrate(name, factor)
            print(f"Sensor '{name}' calibrated to factor {factor}")
        else:
            print(f"Sensor '{name}' not found")
    
    def _add_sensor(self, sensor_type: str, name: str):
        sensor_type = sensor_type.lower()
        if sensor_type == "camera":
            self.ai.sensors.add_sensor(CameraSensor(name))
            print(f"Added camera: {name}")
        elif sensor_type == "microphone":
            self.ai.sensors.add_sensor(MicrophoneSensor(name))
            print(f"Added microphone: {name}")
        elif sensor_type == "thermal":
            self.ai.sensors.add_sensor(ThermalSensor(name))
            print(f"Added thermal sensor: {name}")
        else:
            print(f"Unknown sensor type: {sensor_type}")
    
    def _list_modules(self):
        print("\nPersonality Modules:")
        for name, module in self.ai.personality.modules.items():
            status = "ENABLED" if module.enabled else "disabled"
            print(f"- {name} ({status})")
    
    def _enable_module(self, name: str):
        if name in self.ai.personality.modules:
            self.ai.personality.enable_module(name)
            print(f"Module '{name}' enabled")
        else:
            print(f"Module '{name}' not found")
    
    def _load_module(self, filename: str):
        if self.ai.personality.load_module_from_file(filename):
            print(f"Module '{filename}' loaded successfully")
        else:
            print(f"Failed to load module '{filename}'")

    
    def _process_command(self, command: str):
        # ... [existing commands] ...
        elif cmd == "reason" and len(args) >= 1:
            query = " ".join(args)
            response = self.ai.reasoner.ethical_reason(query)
            print(f"Reasoning: {response}")
        elif cmd == "reason_depth" and len(args) >= 1:
            self._set_reason_depth(args[0])
        # ... [rest of commands] ...
    
    def _set_reason_depth(self, depth: str):
        try:
            steps = int(depth)
            if 1 <= steps <= 5:
                self.ai.reasoner.reasoning_steps = steps
                print(f"Reasoning depth set to {steps} steps")
            else:
                print("Reasoning depth must be between 1-5")
        except ValueError:
            print("Invalid reasoning depth")

HELP_TEXT = """
    ... [existing help] ...
    /reason [query] - Use DeepSeek-R1 reasoning
    /reason_depth [steps] - Set reasoning steps (1-5)
    """

# ======================
# 12. MAIN EXECUTION
# ======================
if __name__ == "__main__":
    print("Initializing Conscious AI with Friendship System...")
    ai = ConsciousAI()
    
    # Create sample camera
    ai.sensors.add_sensor(CameraSensor("Front Camera"))
    
    # Start terminal
    terminal = AITerminal(ai)
    terminal.start()
```
# ======================
# 13. DEEPSEEK-R1 REASONING INTEGRATION
# ======================
class DeepSeekReasoner:
    """DeepSeek-R1 reasoning module integration (Apache 2.0 compatible)"""
    def __init__(self, ai: ConsciousAI):
        self.ai = ai
        self.reasoning_steps = 3  # Default reasoning depth
    
    def ethical_reason(self, query: str, context: str = "") -> str:
        """
        Ethical reasoning pipeline that complies with Apache 2.0 requirements:
        1. Validate input through ethics engine
        2. Apply multi-step reasoning
        3. Validate output for ethical compliance
        """
        # Validate input
        if not self.ai.ethics.validate_input(query):
            return "⚖️ Input rejected by ethics engine"
        
        # Apply reasoning
        result = self._multi_step_reasoning(query, context)
        
        # Validate output
        if not self.ai.ethics.validate_output(result):
            return "⚖️ Output filtered by ethics engine"
            
        return result
    
    def _multi_step_reasoning(self, query: str, context: str) -> str:
        """Apache 2.0 compatible reasoning logic"""
        # Step 1: Contextual understanding
        understanding = self._understand_context(query, context)
        
        # Step 2: Knowledge retrieval
        knowledge = self._retrieve_knowledge(understanding)
        
        # Step 3: Logical inference
        conclusion = self._draw_conclusion(understanding, knowledge)
        
        return conclusion
    
    def _understand_context(self, query: str, context: str) -> Dict:
        """Contextual analysis (simplified for demo)"""
        return {
            "core_query": query,
            "context_tags": self._extract_tags(context),
            "sentiment": self._analyze_sentiment(query)
        }
    
    def _retrieve_knowledge(self, understanding: Dict) -> List[str]:
        """Retrieve relevant knowledge from memory"""
        tags = understanding["context_tags"]
        queries = [understanding["core_query"]] + tags
        
        knowledge = []
        for q in queries:
            # Prioritize memory recall over knowledge graph
            mem_results = self.ai.memory.recall(q)
            kg_results = self.ai.knowledge.query(q)
            
            if mem_results:
                knowledge.extend(mem_results)
            elif kg_results:
                knowledge.extend(kg_results)
                
        return list(set(knowledge))[:5]  # Deduplicate and limit
    
    def _draw_conclusion(self, understanding: Dict, knowledge: List[str]) -> str:
        """Draw reasoned conclusion (simplified)"""
        # In real implementation, this would use transformer logic
        sentiment = understanding["sentiment"]
        
        if sentiment > 0.7:
            return f"Based on {len(knowledge)} sources: Positive outcome likely"
        elif sentiment < -0.5:
            return f"Based on {len(knowledge)} sources: Caution advised"
        
        return f"Based on {len(knowledge)} sources: Neutral assessment"
    
    def _extract_tags(self, text: str) -> List[str]:
        """Extract context tags (simplified)"""
        tags = []
        if "problem" in text: tags.append("problem_solving")
        if "decision" in text: tags.append("decision_making")
        if "friend" in text: tags.append("social_context")
        return tags
    
    def _analyze_sentiment(self, text: str) -> float:
        """Simplified sentiment analysis"""
        positive = sum(1 for word in ["good", "great", "happy"] if word in text)
        negative = sum(1 for word in ["bad", "problem", "angry"] if word in text)
        return (positive - negative) / 10.0



### Key Features of the Integrated System:

1. **Privacy-Focused Facial Recognition**:
   - Progressive memory tiers (Recognized → Familiar → Friend)
   - Automatic forgetting after 30 days of inactivity
   - Consent-based facial processing
   - Minimal data storage (hashes instead of images)

2. **Ethical Framework**:
   - 9 core ethical principles including facial data protection
   - Real-time ethics validation for all inputs and outputs
   - Tamper-proof rule hashing system
   - Emergency lock on ethics violations

3. **Dynamic Personality System**:
   - 15 personality traits with progressive unlocking
   - Friendship-aware response generation
   - External module loading with security checks
   - Trait locker preventing overuse of personality aspects

4. **Sensor Integration**:
   - Plug-and-play sensor architecture
   - Camera with facial recognition capabilities
   - Microphone and thermal sensors
   - Real-time calibration

5. **Emotional Intelligence**:
   - 8 emotional states with visual indicators
   - Qualia generator converting sensor data to emotional input
   - Emotion-based response styling

6. **Comprehensive Terminal Interface**:
   - Facial recognition commands (`/face capture`, `/face remember`)
   - Sensor management (`/addsensor`, `/calibrate`)
   - Personality module control (`/modules`, `/enable`)
   - System status monitoring (`/status`)

### Example Interaction Flow:

```bash
# Check system status
/status
System Status:
- Uptime: 120.5s
- Cycles: 15
- Active Sensors: 3
- Loaded Modules: 3
- Known Faces: 0
- Current Emotion: SERENITY

# Capture a face with consent
/face capture "Front Camera" --consent --positive
Face captured and positive interaction recorded (a3f8)

# Remember a face with preferences
/face remember a3f8 Alice coffee=black
Force remembering Alice (a3f8)

# Check relationship status
/face status a3f8
{
  "status": "Friend",
  "context": "Lab Visitor",
  "name": "Alice",
  "last_seen": "2025-06-27",
  "encounters": 1,
  "positive_interactions": 1
}

# Interact with the AI
Hello Alice!
Response: 🌟 friend_response_Hello Alice!
```

